XML query processing has taken on considerable
importance recently, and several XML databases \cite{tamino,
timber, ibm, microsoft, oracle, excelon, poet} have been
constructed, on a variety of platforms. 
\old{There has naturally been interest benchmarking the performance of 
these systems, and some benchmarks have been proposed}
~\cite{xmach,xmark}.  
\new{There has naturally been an interest in benchmarking the performance of these systems.}
\old{The stated objective of these benchmarks is to assess the 
performance of a given XML database in performing a variety of representative tasks.} 
\new{The focus of currently proposed benchmarks}~\cite{xmach, xmark}
\new{ is to assess the performance of a given XML database in performing a 
variety of representative tasks.}
\old{Such benchmarks are valuable to potential users of a database 
system in providing an indication of the performance the user an expect on their specific application.
The challenge is to devise benchmarks that are sufficiently 
representative of the requirements of "most" users.} 
\new{Such benchmarks are valuable for database users in evaluating
the performance of specific applications. However, this benchmark is targeted for researchers and engineers who
develop XML query processor engines.
The real challenge is not in designing benchmarks for 
specific applications, but in designing a single benchmark that 
meets the requirements of "most" users.}
\old{The TPC series of benchmarks accomplished this, with more or 
less success, for relational database systems.}
\new{The TPC series of benchmarks accomplished this for relational 
database systems.}  
\old{However, no benchmarks have been successful in the realm of ORDBMS 
and OODBMS, we believe on account of the very nature of extensibility 
and user defined functions leading to great heterogeneity in the nature of use.}  
\new{However, no benchmark has been successful in the realm of ORDBMS and OODBMS which have extensibility and user defined functions that lead to great heterogeneity in the nature of use.} 
It is too soon to say whether any of the current XML benchmarks will be successful in this respect - we certainly hope that they will.
\old{One thing that benchmarks of this nature do not typically focus on is the performance of the basic query evaluation operations such as selections, joins, aggregations etc.} 
\new{One aspect that current benchmarks do not focus on is the performance of the basic query evaluation operations such as selections, joins, and aggregations.}  
A ``micro-benchmark'' that highlights the
performance of these basic operations can be very helpful for a
database developer in understanding and evaluating 
alternatives for implementing these basic operations. 
What are the strengths and weaknesses of specific access methods?  Which areas should the developer focus attention on?  What is the basis to choose between two alternative implementations?  Questions of this nature are central to well-engineered systems.  \old{Yet these are at too fine a granularity to be addressed effectively by the global system-level benchmarks.} \new{The global system-level benchmarks, by their nature, are unable to deal with these important issues in detail.}  
The Wisconsin benchmark~\cite{wiss} provided
the database community with an invaluable tool in this regard, for
relational systems. \old{Our goal in this paper is to develop an equivalent tool for XML databases.  Following in the footsteps of \new{In the spirit of} the Wisconsin benchmark,we call the benchmark proposed in this paper the Michigan benchmark.} \new{Our goal in this paper is to develop a comparable
tool for XML databases: the Michigan benchmark.}

Another issue in this regard is the nature of the data in the test database used for the benchmark. 
\old{If the data is carefully specified to represent some "real application",} \new{If the data is specified
to represent a particular "real application",} it is likely to be quite
uncharacteristic for other applications with different data
distributions.  Thus, holistic benchmarks can succeed only if they are able to find a real application with data characteristics that are reasonably representative for a large class of different applications.  
\new{This is important because
the data characteristics can be different from applications to applications.}

Our objective is to create a single heterogeneous data set, along with
a number of queries, \old{each of which exercises carefully chosen portions of the data set, with specific data characteristics.} \new{each of which is chosen to query over portion of data  
that meets specific characteristics.}  Thus, each query \old{tests} \new{will
test} performance with respect to a particular class of data.

Nonetheless, heterogeneity does not mean randomness.  Our attempt is to
provide the necessary attributes to be able to specify queries that
will access precisely the type of data we wish to test.  To keep
the benchmark simple, random number
generators are used sparingly.  This  
benchmark uses random generators for only two attribute values, and all other data
parameters derived from these two generated values.

In relational systems, selectivity\footnote{Selectivity is really not
a characteristic of the data alone, being dependent on the predicate
as well.  For our purposes, it is helpful to think of a specified
predicate and then considering the nature of the data w.r.t. it.}
(including join selectivity) and cardinality are the two
characteristics of primary interest.  (There may be a few additional
secondary characteristics of interest, such as clustering, and size of
tuple/attribute).  In XML databases, besides these characteristics,
there are several others, having to do with the structure, such as
tree fanout and tree depth. A major contribution of this paper is the
identification of such characteristics, and the impact of these
characteristics on system performance.
